{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2449f9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 86)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m86\u001b[0m\n\u001b[1;33m    return f_u, f_v\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# Data-driven inference of the Peregrine Soliton using Neural Networks (TF2 version)\n",
    "\n",
    "import time\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from pyDOE import lhs\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from pyDOE import lhs  # 拉丁超立方采样\n",
    "import tensorflow as tf\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "class PINN(tf.keras.Model):\n",
    "    def __init__(self, layers, lb, ub):\n",
    "        super(PINN, self).__init__()\n",
    "        self.lb = tf.convert_to_tensor(lb, dtype=tf.float32)\n",
    "        self.ub = tf.convert_to_tensor(ub, dtype=tf.float32)\n",
    "        self.hidden = [tf.keras.layers.Dense(l, activation=tf.nn.tanh) for l in layers[1:-1]]\n",
    "        self.out = tf.keras.layers.Dense(layers[-1], activation=None)\n",
    "\n",
    "    def call(self, X):\n",
    "        H = 2.0 * (X - self.lb) / (self.ub - self.lb) - 1.0\n",
    "        for layer in self.hidden:\n",
    "            H = layer(H)\n",
    "        return self.out(H)\n",
    "\n",
    "class PhysicsInformedNN:\n",
    "    def __init__(self, x0, u0, v0, tb, X_f, layers, lb, ub):\n",
    "        self.lb = tf.constant(lb, dtype=tf.float32)\n",
    "        self.ub = tf.constant(ub, dtype=tf.float32)\n",
    "\n",
    "        self.x0 = tf.convert_to_tensor(x0, dtype=tf.float32)\n",
    "        self.t0 = tf.zeros_like(self.x0)\n",
    "        self.u0 = tf.convert_to_tensor(u0, dtype=tf.float32)\n",
    "        self.v0 = tf.convert_to_tensor(v0, dtype=tf.float32)\n",
    "\n",
    "        self.x_lb = tf.zeros_like(tb) + lb[0]\n",
    "        self.t_lb = tf.convert_to_tensor(tb, dtype=tf.float32)\n",
    "        self.x_ub = tf.zeros_like(tb) + ub[0]\n",
    "        self.t_ub = tf.convert_to_tensor(tb, dtype=tf.float32)\n",
    "\n",
    "        self.x_f = tf.convert_to_tensor(X_f[:,0:1], dtype=tf.float32)\n",
    "        self.t_f = tf.convert_to_tensor(X_f[:,1:2], dtype=tf.float32)\n",
    "\n",
    "        self.model = PINN(layers, lb, ub)\n",
    "        self.optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "    def net_uv(self, x, t):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            x = tf.cast(x, tf.float32)\n",
    "            t = tf.cast(t, tf.float32)\n",
    "            X = tf.concat([x, t], axis=1)\n",
    "            uv = self.model(X)\n",
    "            u = uv[:, 0:1]\n",
    "            v = uv[:, 1:2]\n",
    "\n",
    "        u_x = tape.gradient(u, x)\n",
    "        v_x = tape.gradient(v, x)\n",
    "        return u, v, u_x, v_x\n",
    "\n",
    "\n",
    "    def net_f_uv(self, x, t):\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                tape.watch([x, t])\n",
    "                u, v, u_x, v_x = self.net_uv(x, t)\n",
    "\n",
    "                # First derivatives\n",
    "                u_t = tape.gradient(u, t)\n",
    "                v_t = tape.gradient(v, t)\n",
    "\n",
    "            # Second derivatives (using the already computed u_x, v_x)\n",
    "            u_xx = tape.gradient(u_x, x)\n",
    "            v_xx = tape.gradient(v_x, x)\n",
    "\n",
    "            del tape  # Important for persistent tapes\n",
    "\n",
    "            # NLS residuals (split into real and imaginary parts)\n",
    "            f_u = u_t + 0.5*v_xx + (u**2 + v**2)*v  # Imaginary part\n",
    "            f_v = v_t - 0.5*u_xx - (u**2 + v**2)*u  # Real part\n",
    "\n",
    "        return f_u, f_v\n",
    "    \n",
    "    def loss_fn(self):\n",
    "        u0_pred, v0_pred, _, _ = self.net_uv(self.x0, self.t0)\n",
    "        u_lb_pred, v_lb_pred, u_x_lb_pred, v_x_lb_pred = self.net_uv(self.x_lb, self.t_lb)\n",
    "        u_ub_pred, v_ub_pred, u_x_ub_pred, v_x_ub_pred = self.net_uv(self.x_ub, self.t_ub)\n",
    "        f_u_pred, f_v_pred = self.net_f_uv(self.x_f, self.t_f)\n",
    "\n",
    "        loss = tf.reduce_mean((self.u0 - u0_pred)**2) + tf.reduce_mean((self.v0 - v0_pred)**2)\n",
    "        loss += tf.reduce_mean((u_lb_pred - u_ub_pred)**2) + tf.reduce_mean((v_lb_pred - v_ub_pred)**2)\n",
    "        loss += tf.reduce_mean((u_x_lb_pred - u_x_ub_pred)**2) + tf.reduce_mean((v_x_lb_pred - v_x_ub_pred)**2)\n",
    "        loss += tf.reduce_mean(f_u_pred**2) + tf.reduce_mean(f_v_pred**2)\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.loss_fn()\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        return loss\n",
    "\n",
    "    def train(self, nIter):\n",
    "        for it in range(nIter):\n",
    "            loss = self.train_step()\n",
    "            if it % 10 == 0:\n",
    "                print(f\"It {it}, Loss: {loss.numpy():.3e}\")\n",
    "\n",
    "    def predict(self, X_star):\n",
    "        X_star = tf.convert_to_tensor(X_star, dtype=tf.float32)\n",
    "        uv = self.model(X_star)\n",
    "        u_star = uv[:, 0:1].numpy()\n",
    "        v_star = uv[:, 1:2].numpy()\n",
    "        f_u_star, f_v_star = self.net_f_uv(X_star[:, 0:1], X_star[:, 1:2])\n",
    "        return u_star, v_star, f_u_star.numpy(), f_v_star.numpy()\n",
    "\n",
    "# ========================================\n",
    "# Main logic\n",
    "if __name__ == \"__main__\":\n",
    "    lb = np.array([-7.5, -2.0])\n",
    "    ub = np.array([7.5, 2.0])\n",
    "    N0 = 50\n",
    "    N_b = 50\n",
    "    N_f = 20000\n",
    "    layers = [2, 100, 100, 100, 100, 2]\n",
    "\n",
    "\n",
    "    # 加载 .mat 数据\n",
    "    data = scipy.io.loadmat('Data/NLS_PINN1.mat')\n",
    "    x = data['x']  # (256, 1)\n",
    "    t = data['t']  # (100, 1)\n",
    "    usol = data['usol1']  # (256, 100), complex\n",
    "\n",
    "    # 转置后 meshgrid：确保 X 为 256×100 对应 usol\n",
    "    X, T = np.meshgrid(x, t, indexing='ij')  # X, T 都是 (256, 100)\n",
    "\n",
    "    # 拆解复数解为实部和虚部\n",
    "    Exact_u = np.real(usol)  # (256, 100)\n",
    "    Exact_v = np.imag(usol)  # (256, 100)\n",
    "    Exact_h = np.sqrt(Exact_u**2 + Exact_v**2)  # (256, 100)\n",
    "\n",
    "    # 整理输入输出\n",
    "    X_star = np.hstack((X.flatten()[:, None], T.flatten()[:, None]))  # (25600, 2)\n",
    "    u_star = Exact_u.flatten()[:, None]  # (25600, 1)\n",
    "    v_star = Exact_v.flatten()[:, None]  # (25600, 1)\n",
    "    h_star = Exact_h.flatten()[:, None]  # (25600, 1)\n",
    "\n",
    "    # 初始条件采样：选择 t=0\n",
    "    N0 = 100  # 初始条件点数\n",
    "    idx_x = np.random.choice(x.shape[0], N0, replace=False)\n",
    "    x0 = x[idx_x, :]  # (N0, 1)\n",
    "    u0 = Exact_u[idx_x, 0:1]  # t=0 处的实部\n",
    "    v0 = Exact_v[idx_x, 0:1]  # t=0 处的虚部\n",
    "\n",
    "    # 边界条件采样（沿 x 边界选取多个 t）\n",
    "    N_b = 80\n",
    "    idx_t = np.random.choice(t.shape[0], N_b, replace=False)\n",
    "    tb = t[idx_t, :]  # (N_b, 1)\n",
    "\n",
    "    # 网格边界（用于拉丁超立方）\n",
    "    lb = X_star.min(0)  # [x_min, t_min]\n",
    "    ub = X_star.max(0)  # [x_max, t_max]\n",
    "\n",
    "    # 方程残差采样点：拉丁超立方采样\n",
    "    N_f = 20000\n",
    "    X_f = lb + (ub - lb) * lhs(2, N_f)  # (N_f, 2)\n",
    "\n",
    "    # 最终结果：\n",
    "    # x0, u0, v0 — 初始条件\n",
    "    # tb — 时间边界条件点\n",
    "    # X_f — 方程残差点\n",
    "\n",
    "\n",
    "    model = PhysicsInformedNN(x0, u0, v0, tb, X_f, layers, lb, ub)\n",
    "    start_time = time.time()\n",
    "    model.train(5000)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Training time: {elapsed:.4f}s\")\n",
    "\n",
    "    u_pred, v_pred, f_u_pred, f_v_pred = model.predict(X_star)\n",
    "    h_pred = np.sqrt(u_pred**2 + v_pred**2)\n",
    "    H_pred = griddata(X_star, h_pred.flatten(), (X, T), method='cubic')\n",
    "\n",
    "    error_u = np.linalg.norm(u_star-u_pred,2)/np.linalg.norm(u_star,2)\n",
    "    error_v = np.linalg.norm(v_star-v_pred,2)/np.linalg.norm(v_star,2)\n",
    "    error_h = np.linalg.norm(h_star-h_pred,2)/np.linalg.norm(h_star,2)\n",
    "    error_H = np.linalg.norm(Exact_h[100,:]-H_pred[100,:],2)/np.linalg.norm(Exact_h[100,:],2)\n",
    "\n",
    "    print(f'Error u: {error_u:e}')\n",
    "    print(f'Error v: {error_v:e}')\n",
    "    print(f'Error h: {error_h:e}')\n",
    "    print(f'Error at time step = 0: {error_H:e}')\n",
    "\n",
    "    plt.imshow(H_pred, interpolation='nearest', cmap='rainbow',\n",
    "               extent=[lb[0], ub[0], lb[1], ub[1]], origin='lower', aspect='auto')\n",
    "    plt.title('|h(x,t)|')\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$t$')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(\"predicted_peregrine_solition.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(x, Exact_h[100,:], 'b-', linewidth = 2, label = 'Exact')\n",
    "    plt.plot(x, H_pred[100,:], 'r--', linewidth = 2, label = 'Prediction')\n",
    "    plt.title('$t = 0$', fontsize=10)\n",
    "    plt.xlabel('$x$')\n",
    "    plt.ylabel('$|h(x,t)|$')\n",
    "    plt.legend(frameon=False)\n",
    "    plt.savefig(\"predicted_vs_exact_peregrine_time_step_0.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bf9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
